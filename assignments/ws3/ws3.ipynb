{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562d7c41",
   "metadata": {},
   "source": [
    "# CIS 1902 Worksheet 3: Pandas\n",
    "\n",
    "**Due Friday March 31, 2023 11:59 pm EST**\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Work with Pandasâ€™ Series and DataFrames\n",
    "- Perform data preprocessing and cleaning\n",
    "- Practice exploring on a partially-familiar dataset\n",
    "- Decide how to visually represent data in a clear way\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1fb81",
   "metadata": {},
   "source": [
    "**First, make a copy of this Colab to your Google Drive by clicking \"Copy to Drive\" in the upper left or `File -> save a copy in Drive` so you can save any changes you make.**\n",
    "\n",
    "- **Name:** TODO\n",
    "- **PennKey:** TODO\n",
    "- **Number of hours spent on homework** TODO\n",
    "\n",
    "Collaboration is NOT permitted.\n",
    "\n",
    "In the functions below the \"NotImplementedError\" exception is raised, for\n",
    "you to fill in. The interpreter will not consider the empty code blocks\n",
    "as syntax errors, but the \"NotImplementedError\" will be raised if you\n",
    "call the function. You will replace these raised exceptions with your\n",
    "code completing the function as described in the docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf3379",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "From either the course website or Stack Overflow, download the zip file for 2025's Stack Overflow Survey.  On your computer, unzip the file and move the two relevant files (`survey_results_public.csv` and `survey_results_schema.csv`) to be in the same directory as this worksheet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19dc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create `df` and `schema_df` by reading the two csvs you've moved to this directory\n",
    "df = None\n",
    "schema_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182bdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows you to see all of the columns in df\n",
    "pd.set_option('display.max_columns', 85)\n",
    "pd.set_option('display.max_rows', 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64bcde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d014d",
   "metadata": {},
   "source": [
    "## Task 1: Choosing topic of study\n",
    "\n",
    "Using techniques learned in class, explore the contents and layout of the dataframe `df`.  When you feel more familiar with `df`, pick two topics for the purpose of exploring a possible correlation.  You may also compare more than two topics if desired.\n",
    "\n",
    "**Hint**: you may want to find a way to display all the survey questions before choosing your topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6596f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO TASK 1: use this cell (+ others if you would like) to explore the dataset\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "My topics will be: \n",
    "TODO: replace this line with the topics you've chosen\n",
    "\n",
    "The columns that I will be likely using are these:\n",
    "TODO: replace this line with the column names in `df` that you will likely use.  \n",
    "(while you're free to change your mind later, it's good to think ahead about what quantative values correspond to the information we're seeking)\n",
    "\"\"\"; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a721e2e",
   "metadata": {},
   "source": [
    "## Task 2: Data Preprocessing\n",
    "\n",
    "Regarding datasets, you will almost always run into invalid entries, such as missing or out-of-range values.  It's always a good idea to see what values we are working with before we attempt to manipulate the dataframe.\n",
    "\n",
    "Most likely, your dataset (like this one) will be too large for you to manually examine each entry.  Instead, we can look at the unique values under each column you've chosen in task 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ae89b",
   "metadata": {},
   "source": [
    "Here are two examples in the cell below.  We're calling the method `unique()` on a Series object (from indexing into the dataframe).  `duration_example`'s type is an ndarray.  In this context, these are the possible answers for the question \"*How long have you used Stack Overflow?*\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a63ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO run this cell to see the output\n",
    "duration_example = df['SODuration'].unique()\n",
    "print('How long have you used Stack Overflow:\\n' + str(duration_example))\n",
    "print('--------------------------------------------------------------------------')\n",
    "years_example = df['YearsCode'].unique()\n",
    "print('How many years have you been coding in total?:\\n' + str(years_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d5290c",
   "metadata": {},
   "source": [
    "You can see that for `duration_example` and `years_example`, there are a number of \"valid\" answers, and then `nan`.  `nan` stands for \"not a number,\" which doesn't seem to make much sense in an array of strings, but it's common for `nan` to represent missing values in a dataset.  Not all datasets use `nan` to indicate missing values, so you need to check your dataset to see what it uses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO TASK 2: display the unique values of your columns from Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f1047",
   "metadata": {},
   "source": [
    "If there is `nan` or any weird-looking values displayed, you're probably dealing with an incomplete dataset.  Sometimes, it makes sense to not modify the missing values (e.g. when you're not concerned about the column it belongs to), but there are times when you need to address it.  Here's a sample table:\n",
    "\n",
    "| ResponseId    |  ...         | YearsCode     | SODuration             | \n",
    "|-------------- |--------------|---------------|------------------------|\n",
    "| 0             |  ...         | 25.0          | nan                    |\n",
    "| 1             |  ...         | nan           | Between 5 and 10 years |\n",
    "| 2             |  ...         | nan           | nan                    |\n",
    "| 3             |  ...         | 1.0           | Less than one year     |\n",
    "\n",
    "Note that the 4th row is the only one with useful information if our goal was to compare years coded with years spent on Stack Overflow.  The 3rd row is useless because it contains no relevant information, and the first two rows are useless because they contain one value, but don't have a second value that may give information on the *relationship* between the two questions. \n",
    "\n",
    "Therefore, before we perform any data analysis, we should remove the rows that won't help us.  We can see from this example that any row missing values in either `YearsCode` or `SODuration` (or missing from both) should be removed.  We can call a handy method that removes `nan` values without having us iterate over the dataframe ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33846a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even though this function is called on your dataframe, it does not actually modify df\n",
    "dropna_example = df.dropna(how='any', subset=['SODuration', 'YearsCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69a33a",
   "metadata": {},
   "source": [
    "In the cell above, we save the result of this function in a new dataframe: `dropna_example`.  We passed in the following positional arguments:\n",
    "- `subset` has a list of columns that it will check for a `nan` value in.  Its default value is the list of all columns in your dataframe.\n",
    "- `how` can either be set to `'any'` or `'all'`.  If it's set to \"any\", then it will drop the row if any of the values in the subset.  If it's set to \"all\", then it will drop the row if `nan` is found in all columns in subset.\n",
    "\n",
    "we can see the results of this operation by checking the unique values of the columns we just cleaned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_example = dropna_example['SODuration'].unique()\n",
    "print('How long have you used Stack Overflow:\\n' + str(duration_example))\n",
    "print('--------------------------------------------------------------------------')\n",
    "years_example = dropna_example['YearsCode'].unique()\n",
    "print('How many years have you been coding in total?:\\n' + str(years_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3d73e",
   "metadata": {},
   "source": [
    "Using the example as a model, perform the same steps for your own columns.  Remember that almost every pandas operation creates a new dataframe instead of editing the existing one, so either save it in a new variable or add the argument `inplace = True`.  Make sure to also confirm that you've successfully cleaned your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb56aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO perform your preprocessing steps on your dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c4bb1",
   "metadata": {},
   "source": [
    "## Task 3: Dataframe Operations\n",
    "\n",
    "Now that your dataframe is ready to be analyzed, it's time to decide how you're going to represent the data.  A few questions to consider:\n",
    "1. What relationship am I trying to represent when I create my plot?  What two things am I comparing? (they will become your x and y axes)\n",
    "2. Would it make more sense to generate more than one plot?  Why or why not?\n",
    "3. What style of plot would most clearly represent the relation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93faf4d",
   "metadata": {},
   "source": [
    "While you aren't required to answer these in the worksheet, I **highly** suggest you think through at least one question before you move forward, because the answer can influence what actions you'll take next, especially since the remainder of the task is open-ended.  You will also be asked to record your specific reasonings behind the choices you make in when completing this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "51965417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you choose to do so, you may write down any notes here:\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12281df",
   "metadata": {},
   "source": [
    "Using the Stack Overflow example we went over in lecture, perform the necessary DataFrame operations to get your data organized in a way that is easily graphed.  You may insert more code cells if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d4990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO reshape your dataframe such that you can use it to create your plot(s) for the next task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd680e5",
   "metadata": {},
   "source": [
    "## Task 4: Plotting and Reflection\n",
    "\n",
    "Now that your dataframe is set up, it's time to make your plot(s)!  Add your code to the cell below (you may always add more cells if that helps organization).  Make sure your plots are legible and properly labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make your plot(s) here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7b4cd",
   "metadata": {},
   "source": [
    "Once you're satisfied, answer the following questions using the triple quoted string in the cell below:\n",
    "1. Do your plot(s) indicate a correlation?  Why or why not?  \n",
    "2. Why did you choose to make as many plots as you did (1 versus more than 1)?\n",
    "3. Why did you choose a particular format for your plot(s) (e.g. bar graph, scatterplot, line graph, multi-line)?\n",
    "4. What was easier to do when working with Pandas?  What areas were more challenging/prone to getting stuck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8300fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO answer the 4 questions above in this cell:\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa691b",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Afer you have completed the worksheet, download the Colab notebook as a ws3.py file by going to File -> Download .py. Make sure you also download your plot(s) to upload with your Python file - the file name for the plots should not matter.  Then submit your ws3.py file and any images of saved plots to Gradescope.\n",
    "\n",
    "Since this assignment is open-ended, the worksheet will be manually graded.\n",
    "\n",
    "Note: since you will be submitting Colab-formatted .py files, we will not be grading code style for this assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
